{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "fashion_mnist = tf.keras.datasets.fashion_mnist\n",
    "(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()\n",
    "train_images = (train_images / 255.0).astype(np.float32)\n",
    "test_images = (test_images / 255.0).astype(np.float32)\n",
    "train_labels = tf.keras.utils.to_categorical(train_labels)\n",
    "test_labels = tf.keras.utils.to_categorical(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SIZE = 28\n",
    "\n",
    "class Model(tf.Module):\n",
    "\n",
    "  def __init__(self):\n",
    "    self.model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Flatten(input_shape=(IMG_SIZE, IMG_SIZE), name='flatten'),\n",
    "        tf.keras.layers.Dense(128, activation='relu', name='dense_1'),\n",
    "        tf.keras.layers.Dense(10, name='dense_2')\n",
    "    ])\n",
    "\n",
    "    self.model.compile(\n",
    "        optimizer='adam',\n",
    "        loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True))\n",
    "\n",
    "  # The `train` function takes a batch of input images and labels.\n",
    "  @tf.function(input_signature=[\n",
    "      tf.TensorSpec([None, IMG_SIZE, IMG_SIZE], tf.float32),\n",
    "      tf.TensorSpec([None, 10], tf.float32),\n",
    "  ])\n",
    "  def train(self, x, y):\n",
    "    with tf.GradientTape() as tape:\n",
    "      prediction = self.model(x)\n",
    "      loss = self.model.loss(y, prediction)\n",
    "    gradients = tape.gradient(loss, self.model.trainable_variables)\n",
    "    self.model.optimizer.apply_gradients(\n",
    "        zip(gradients, self.model.trainable_variables))\n",
    "    result = {\"loss\": loss}\n",
    "    return result\n",
    "\n",
    "  @tf.function(input_signature=[\n",
    "      tf.TensorSpec([None, IMG_SIZE, IMG_SIZE], tf.float32),\n",
    "  ])\n",
    "  def infer(self, x):\n",
    "    logits = self.model(x)\n",
    "    probabilities = tf.nn.softmax(logits, axis=-1)\n",
    "    return {\n",
    "        \"output\": probabilities,\n",
    "        \"logits\": logits\n",
    "    }\n",
    "  \n",
    "  \n",
    "  @tf.function(input_signature=[tf.TensorSpec(shape=[], dtype=tf.string)])\n",
    "  def save(self, checkpoint_path):\n",
    "    tensor_names = [weight.name for weight in self.model.weights]\n",
    "    tensors_to_save = [weight.read_value() for weight in self.model.weights]\n",
    "    tf.raw_ops.Save(\n",
    "        filename=checkpoint_path, tensor_names=tensor_names,\n",
    "        data=tensors_to_save, name='save')\n",
    "    return {\n",
    "        \"checkpoint_path\": checkpoint_path\n",
    "    }\n",
    "\n",
    "  @tf.function(input_signature=[tf.TensorSpec(shape=[], dtype=tf.string)])\n",
    "  def restore(self, checkpoint_path):\n",
    "    restored_tensors = {}\n",
    "    for var in self.model.weights:\n",
    "      restored = tf.raw_ops.Restore(\n",
    "          file_pattern=checkpoint_path, tensor_name=var.name, dt=var.dtype,\n",
    "          name='restore')\n",
    "      var.assign(restored)\n",
    "      restored_tensors[var.name] = restored\n",
    "    return restored_tensors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_interpreter (infer_fn):\n",
    "    correct_predictions = 0\n",
    "    true_labels = np.argmax(test_labels, axis=1)\n",
    "    for i in range(len(test_images)):\n",
    "        input_data = test_images[i].reshape(1, 28, 28) \n",
    "        output_data=infer_fn(x=input_data)\n",
    "        predicted_label = np.argmax(output_data[\"output\"])\n",
    "        if predicted_label == true_labels[i]:\n",
    "            correct_predictions += 1\n",
    "    accuracy = correct_predictions / len(test_images)\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model (model):\n",
    "    result = model.infer(test_images)\n",
    "    predictions = result[\"output\"].numpy() \n",
    "    predicted_labels = np.argmax(predictions, axis=1)\n",
    "    true_labels = np.argmax(test_labels, axis=1)\n",
    "    accuracy = np.mean(predicted_labels == true_labels)\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To restore tflite model fully:\n",
    "1. load tflite into interpreter (if tflite file is made from keras model)\n",
    "2. load tflite + checkpoint into interpreter (checkpoint cannot be from an interpreter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8792"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#load interpreter from tflite\n",
    "interpreter = tf.lite.Interpreter(model_path=\"models/orig_model_epochs_30_batch_100.tflite\")\n",
    "interpreter.allocate_tensors()\n",
    "initial_accuracy=evaluate_interpreter(interpreter.get_signature_runner(\"infer\"))\n",
    "initial_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#how to save and load from checkpoint (optional)\n",
    "# model.save('tmp/model.ckpt')\n",
    "# restore = interpreter.get_signature_runner(\"restore\")\n",
    "# restore(checkpoint_path=np.array(\"tmp/model.ckpt\", dtype=np.string_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1513\n"
     ]
    }
   ],
   "source": [
    "#create new model with random weights\n",
    "model = Model()\n",
    "print(evaluate_model(model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8772\n"
     ]
    }
   ],
   "source": [
    "#assign loaded interpreter tensors with model\n",
    "tensor_details = interpreter.get_tensor_details()\n",
    "trainable_indices = [idx for idx,d in enumerate(tensor_details) if \"variable\" in d[\"name\"].lower()]\n",
    "weights = [interpreter.get_tensor(i) for i in trainable_indices]\n",
    "\n",
    "model.model.layers[1].set_weights([weights[1], weights[0]]) \n",
    "model.model.layers[2].set_weights([weights[3], weights[2]])  \n",
    "print(evaluate_model(model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TFLite weight 0 shape: (128,)\n",
      "TFLite weight 1 shape: (784, 128)\n",
      "TFLite weight 2 shape: (10,)\n",
      "TFLite weight 3 shape: (128, 10)\n",
      "Layer dense_1 weights shapes: [(784, 128), (128,)]\n",
      "Layer dense_2 weights shapes: [(128, 10), (10,)]\n"
     ]
    }
   ],
   "source": [
    "#checkout weight dimensions\n",
    "for idx, w in enumerate(weights):\n",
    "    print(f\"TFLite weight {idx} shape: {w.shape}\")\n",
    "for layer in [model.model.layers[1], model.model.layers[2]]:\n",
    "    layer_w = layer.get_weights()\n",
    "    print(f\"Layer {layer.name} weights shapes: {[w.shape for w in layer_w]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished 10 epochs\n",
      "  loss: 0.127\n",
      "Finished 20 epochs\n",
      "  loss: 0.075\n",
      "Finished 30 epochs\n",
      "  loss: 0.089\n",
      "Finished 40 epochs\n",
      "  loss: 0.076\n",
      "Finished 50 epochs\n",
      "  loss: 0.054\n",
      "0.8752\n"
     ]
    }
   ],
   "source": [
    "NUM_EPOCHS = 50\n",
    "BATCH_SIZE = 100\n",
    "epochs = np.arange(1, NUM_EPOCHS + 1, 1)\n",
    "losses = np.zeros([NUM_EPOCHS])\n",
    "\n",
    "train_ds = tf.data.Dataset.from_tensor_slices((train_images, train_labels))\n",
    "train_ds = train_ds.batch(BATCH_SIZE)\n",
    "\n",
    "for i in range(NUM_EPOCHS):\n",
    "  for x,y in train_ds:\n",
    "    result = model.train(x, y)\n",
    "\n",
    "  losses[i] = result['loss']\n",
    "  if (i + 1) % 10 == 0:\n",
    "    print(f\"Finished {i+1} epochs\")\n",
    "    print(f\"  loss: {losses[i]:.3f}\")\n",
    "print(evaluate_model(model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: saved_model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Importing a function (__inference_internal_grad_fn_91529) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_internal_grad_fn_91557) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n"
     ]
    }
   ],
   "source": [
    "SAVED_MODEL_DIR = \"saved_model\"\n",
    "\n",
    "tf.saved_model.save(\n",
    "    model,\n",
    "    SAVED_MODEL_DIR,\n",
    "    signatures={\n",
    "        'train':\n",
    "            model.train.get_concrete_function(),\n",
    "        'infer':\n",
    "            model.infer.get_concrete_function(),\n",
    "        'save':\n",
    "            model.save.get_concrete_function(),\n",
    "        'restore':\n",
    "            model.restore.get_concrete_function(),\n",
    "    })\n",
    "\n",
    "# Convert the model\n",
    "converter = tf.lite.TFLiteConverter.from_saved_model(SAVED_MODEL_DIR)\n",
    "converter.target_spec.supported_ops = [\n",
    "    tf.lite.OpsSet.TFLITE_BUILTINS,  # enable TensorFlow Lite ops.\n",
    "    tf.lite.OpsSet.SELECT_TF_OPS  # enable TensorFlow ops.\n",
    "]\n",
    "converter.experimental_enable_resource_variables = True\n",
    "tflite_model = converter.convert()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Fine-tuned TFLite model saved as: models/finetuned_model_epochs_50_batch_100.tflite\n"
     ]
    }
   ],
   "source": [
    "tflite_model_path = f\"models/finetuned_model_epochs_{NUM_EPOCHS}_batch_{BATCH_SIZE}.tflite\"\n",
    "with open(tflite_model_path, \"wb\") as f:\n",
    "    f.write(tflite_model)\n",
    "print(f\"✅ Fine-tuned TFLite model saved as: {tflite_model_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fashion_mnist = tf.keras.datasets.fashion_mnist\n",
    "(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()\n",
    "train_images = (train_images / 255.0).astype(np.float32)\n",
    "test_images = (test_images / 255.0).astype(np.float32)\n",
    "train_labels = tf.keras.utils.to_categorical(train_labels)\n",
    "test_labels = tf.keras.utils.to_categorical(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "interpreter = tf.lite.Interpreter(model_path=\"models/trained_model_non_concrete.tflite\")\n",
    "interpreter.allocate_tensors()\n",
    "input_details = interpreter.get_input_details()\n",
    "output_details = interpreter.get_output_details()\n",
    "print(\"Input details:\", input_details[0]['shape'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_native (infer_fn):\n",
    "    correct_predictions = 0\n",
    "    true_labels = np.argmax(test_labels, axis=1)\n",
    "    for i in range(len(test_images)):\n",
    "        input_data = test_images[i].reshape(1, 28, 28) \n",
    "        output_data=infer_fn(x=input_data)\n",
    "        predicted_label = np.argmax(output_data[\"output\"])\n",
    "        if predicted_label == true_labels[i]:\n",
    "            correct_predictions += 1\n",
    "    accuracy = correct_predictions / len(test_images)\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_accuracy=evaluate_native(interpreter.get_signature_runner(\"infer\"))\n",
    "print(f\"Initial Model Accuracy: {initial_accuracy:.4f}\")\n",
    "\n",
    "NUM_EPOCHS = 5\n",
    "BATCH_SIZE = 32\n",
    "epochs = np.arange(1, NUM_EPOCHS + 1, 1)\n",
    "losses = np.zeros([NUM_EPOCHS])\n",
    "\n",
    "train_ds = tf.data.Dataset.from_tensor_slices((train_images, train_labels))\n",
    "train_ds = train_ds.batch(BATCH_SIZE)\n",
    "\n",
    "train_fn = interpreter.get_signature_runner(\"train\")\n",
    "\n",
    "for i in range(NUM_EPOCHS):\n",
    "  for x,y in train_ds:\n",
    "    result = train_fn(x=x, y=y)\n",
    "\n",
    "  losses[i] = result['loss']\n",
    "  print(f\"Finished {i+1} epochs\")\n",
    "  print(f\"  loss: {losses[i]:.3f}\")\n",
    "evaluate_native(interpreter.get_signature_runner(\"infer\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(epochs, losses, label='Finetraining')\n",
    "plt.ylim([0, max(plt.ylim())])\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss [Cross Entropy]')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save to ckpt-> save to tflite\n",
    "save_fn = interpreter.get_signature_runner(\"save\")\n",
    "checkpoint_path = \"models/trained_weights.ckpt\"\n",
    "\n",
    "save_fn(checkpoint_path=np.array(checkpoint_path, dtype=np.string_))\n",
    "print(f\"✅ Fine-tuned weights saved to {checkpoint_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create model (must match original one)\n",
    "model = tf.keras.Sequential([\n",
    "   tf.keras.layers.Flatten(input_shape=(28, 28), name='flatten'),\n",
    "    tf.keras.layers.Dense(128, activation='relu', name='dense_1'),\n",
    "    tf.keras.layers.Dense(10, name='dense_2')\n",
    "])\n",
    "model.compile(optimizer='adam', loss=tf.keras.losses.CategoricalCrossentropy()) \n",
    "\n",
    "IMG_SIZE = 28\n",
    "@tf.function(input_signature=[\n",
    "    tf.TensorSpec([None, IMG_SIZE, IMG_SIZE], tf.float32),\n",
    "    tf.TensorSpec([None, 10], tf.float32),\n",
    "])\n",
    "def train(x, y):\n",
    "    with tf.GradientTape() as tape:\n",
    "        prediction = model(x)\n",
    "        loss = model.loss(y, prediction)\n",
    "    gradients = tape.gradient(loss, model.trainable_variables)\n",
    "    model.optimizer.apply_gradients(\n",
    "        zip(gradients, model.trainable_variables))\n",
    "    result = {\"loss\": loss}\n",
    "    return result\n",
    "\n",
    "@tf.function(input_signature=[\n",
    "    tf.TensorSpec([None, IMG_SIZE, IMG_SIZE], tf.float32),\n",
    "])\n",
    "def infer(x):\n",
    "    logits = model(x)\n",
    "    probabilities = tf.nn.softmax(logits, axis=-1)\n",
    "    return {\n",
    "        \"output\": probabilities,\n",
    "        \"logits\": logits\n",
    "    }\n",
    "@tf.function(input_signature=[tf.TensorSpec(shape=[], dtype=tf.string)])\n",
    "def save(checkpoint_path):\n",
    "    tensor_names = [weight.name for weight in model.weights]\n",
    "    tensors_to_save = [weight.read_value() for weight in model.weights]\n",
    "    tf.raw_ops.Save(\n",
    "        filename=checkpoint_path, tensor_names=tensor_names,\n",
    "        data=tensors_to_save, name='save')\n",
    "    return {\n",
    "        \"checkpoint_path\": checkpoint_path\n",
    "    }\n",
    "\n",
    "@tf.function(input_signature=[tf.TensorSpec(shape=[], dtype=tf.string)])\n",
    "def restore(checkpoint_path):\n",
    "    restored_tensors = {}\n",
    "    for var in model.weights:\n",
    "        restored = tf.raw_ops.Restore(\n",
    "            file_pattern=checkpoint_path, tensor_name=var.name, dt=var.dtype,\n",
    "            name='restore')\n",
    "        var.assign(restored)\n",
    "        restored_tensors[var.name] = restored\n",
    "    return restored_tensors\n",
    "\n",
    "signatures = {\n",
    "    'train': train,\n",
    "    'infer': infer,\n",
    "    'save': save,\n",
    "    'restore': restore\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#copy tensors into model variable\n",
    "tensor_details = interpreter.get_tensor_details()\n",
    "trainable_indices = [idx for idx,d in enumerate(tensor_details) if \"variable\" in d[\"name\"].lower()]\n",
    "weights = [interpreter.get_tensor(i) for i in trainable_indices]\n",
    "model.layers[1].set_weights([weights[1], weights[0]]) \n",
    "model.layers[2].set_weights([weights[3], weights[2]])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "SAVED_MODEL_DIR = \"saved_model\"\n",
    "\n",
    "tf.saved_model.save(\n",
    "    model,\n",
    "    SAVED_MODEL_DIR,\n",
    "    signatures=signatures\n",
    ")\n",
    "converter = tf.lite.TFLiteConverter.from_saved_model(SAVED_MODEL_DIR)\n",
    "converter.target_spec.supported_ops = [\n",
    "    tf.lite.OpsSet.TFLITE_BUILTINS,  # Enable TensorFlow Lite ops.\n",
    "    tf.lite.OpsSet.SELECT_TF_OPS  # Enable TensorFlow ops.\n",
    "]\n",
    "converter.experimental_enable_resource_variables = True\n",
    "\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "# Save the TFLite model\n",
    "tflite_model_path = \"models/finetuned_model.tflite\"\n",
    "with open(tflite_model_path, \"wb\") as f:\n",
    "    f.write(tflite_model)\n",
    "\n",
    "print(f\"✅ Fine-tuned TFLite model with signatures saved as: {tflite_model_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "another_interpreter = tf.lite.Interpreter(model_content=tflite_model)\n",
    "another_interpreter.allocate_tensors()\n",
    "print(\"Model Signatures:\", another_interpreter.get_signature_list())\n",
    "infer_fn_new = another_interpreter.get_signature_runner(\"infer\")\n",
    "#optional as tflite contains the weights\n",
    "# restore_fn_new = another_interpreter.get_signature_runner(\"restore\")\n",
    "# restore_fn_new(checkpoint_path=np.array(checkpoint_path, dtype=np.string_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_accuracy= evaluate_native(infer_fn_new)\n",
    "print(f\"Final Model Accuracy: {new_accuracy:.4f}\")\n",
    "print(f\"Model Improvement: {new_accuracy-initial_accuracy:.4f}\")\n",
    "end_time = time.time()\n",
    "print(f\"Total script execution time: {end_time - start_time:.2f} seconds\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
